---
title: "Making Trees"
author: "Kim Roth / Loren Rhodes"
date: "10/17/2017"
output: html_document
---
Name(s): Wendy Chen

**Data setup**

```{r setup, include=FALSE}
library(tidyverse)
library(mosaic)
library(rpart) #where the tree routines are
library(partykit) #for good tree visualization
library(sp)
library(randomForest)
```

We will be using data about patients with acute hepatitis and trying to classify which explanatory variables predict death of a patient.

Load the cleaned data.
```{r}
library(readr)
hepatitisCleanNoNA
```

Now you'll need to take all of the quantitative variables that are categorical and use as.factor like in the example from class to make R treat them like categories called factors (needed for randomForests).  
```{r}
hepatitisCleanNoNA=mutate(hepatitisCleanNoNA, Sex=as.factor(Sex), Class=as.factor(Class), Age=as.factor(Age), Steriod=as.factor(Steriod), Anorexia=as.factor(Anorexia), Antivirals=as.factor(Antivirals), Fatigue=as.factor(Fatigue), Malaise=as.factor(Malaise), LiverBig=as.factor(LiverBig), SpeelPalpable=as.factor(SpeelPalpable), Spiders=as.factor(Spiders), Acvites=as.factor(Acvites), Varacises=as.factor(Varacises), Bilirubis=as.factor(Bilirubis), Histology=as.factor(Histology))
head(hepatitisCleanNoNA)
```


Now let's pick a training set and a test set.
```{r}
set.seed(4) #setseed(10) #insert a number here. I reccomend you use your birthday. This makes R pick the same set if you rerun the analysis. Since we are trying to write about specific results here we want to do that.
n=nrow(hepatitis)
testSample=sample.int(n,size=round(.2*n))
train=hepatitis[-testSample,]
test=hepatitis[testSample,]

```

Our response variable will be Class. It has two values, 2=LIVE and 1=DIE.  Note for sex, 2-male and 1=female. For yes/no categorical variables 2=No and 1=yes.


**Project directions**
Your job is to write a short paper talking about this data and trees made with it.

Begin with a description of the data set. You will need to look up the variables that show up in the paper to see what they mean so you can talk about them in context.
  In the data set, class tells the people if the patient lived or died. Age gives infomration on how old the patient is. Sex is whether or not the patient is a male or a female. Under Steroids, we find out if the paitent were taking them or not. Antivirals states if a person was taking antiviral medicine. The variable fatigue says if the patient is experiencing fatigue and malaise tells us if the patiet has any discomfort or pain. Anorexia gives us information on whether the patient was anorexic. Liver Big states if the patient's liver was unusually large and Liver firm questions if the person's liver was firm or not. In this case, a firm liver is consider as abnormal. Spleen palpable questions if the spleen can be found by palpitation. The data set also includes Spider nerves which tells the readers if a patient had spider nerves which is a collection of dillated blood vessles close to the skin. Ascites asks if a patient have fluid buildup in the abdominal cavity. Varices tells us if the patient has enlarge views in the stomach or the throat. Bilibrubin is the measure of that substance in the patient's blood. Histology says if the liver looks normal or not.

First, make a tree in R using all possible predcitors predicting Class with the Gini coefficent. For the tree you will show a picture of the tree, show how it will classify one case in the data set, and  evaluate the prediction ability on the test and training data using the confusion matrix. 

```{r}
predictTrain=predict(TreeGender,train, type="class")
conf=tally(predictTrain~ train$Sex)
(sum(diag(conf)))/nrow(train)
predictTest=predict(TreeGender,test, type="class")
conf2=tally(predictTest~ test$Sex)
(sum(diag(conf2)))/nrow(test)

predictTrain=predict(TreeGender,train, type="class")
conf=tally(predictTrain~ train$Age)
(sum(diag(conf)))/nrow(train)
predictTest=predict(TreeGender,test, type="class")
conf2=tally(predictTest~ test$Age)
(sum(diag(conf2)))/nrow(test)
```


```{r}
tally(~Sex,data=train, format="proportion") 
tally(~Age,data=train, format="proportion")
```

```{r}
tally(~Sex,data=test, format="proportion")
tally(~Age, data=test, format = "proportion")
```

```{r}
TreeGender=rpart(Age~Sex, data=train)
TreeGender
plot(as.party(TreeGender))

TreeGender=rpart(Sex~Age, data=train)
TreeGender
plot(as.party(TreeGender))
```


Second, make a tree with the information gain in R.

```{r}
TreeHR=rpart(Age~Sex, data=train, control=rpart.control(maxdepth=1))
TreeHR
plot(as.party(TreeHR))
```


Third, make a tree in Weka (copy and paste the Weka text output into R).  The csv file will need a column name for the first column (call it Row), which is the one you can delete. You might convert most of the variables to nominal type (Filters -> Unsupervised -> attribute -> NumericToNominal and specify the column numbers) for nicer trees. You may then remove the Row number column that is explicit in the data.    Recall the decision tree algorithm is J48 under Classifiers -> Trees.

```{r}

```


Fourth, make a random forest in R. 
```{r}
TreeO=rpart(Sex~., data=train)
TreeO
plot(as.party(TreeO))
```


Finally, compare the first tree to the trees to those generated in the second, third and fourth steps. Your comparison will include what variables are new to the tree/importance list of the forest and the prediction ability on the trainig and test set.  
  From the first tree to the other trees, one can see that more variables are shown.

Conclude with what variables seem to be important to predicting Class and which tree you think should be used and why.
  The variable of age and sex seems to be important to predicting whether or not a patient lived or not. The tree that I think should be used is the last tree as it tells R to use all of the other variables.
